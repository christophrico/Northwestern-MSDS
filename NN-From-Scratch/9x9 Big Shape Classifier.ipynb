{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uv4F3da0DFLy",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RG\n",
    "[\n",
    "    (\n",
    "        0,\n",
    "        [\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "        ],\n",
    "        0,\n",
    "        \"A\",\n",
    "        0,\n",
    "        \"A\",\n",
    "    ),\n",
    "    (\n",
    "        1,\n",
    "        [\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "        ],\n",
    "        1,\n",
    "        \"B\",\n",
    "        1,\n",
    "        \"B\",\n",
    "    ),\n",
    "    (\n",
    "        2,\n",
    "        [\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "        ],\n",
    "        2,\n",
    "        \"C\",\n",
    "        2,\n",
    "        \"C\",\n",
    "    ),\n",
    "    (\n",
    "        3,\n",
    "        [\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "        ],\n",
    "        3,\n",
    "        \"D\",\n",
    "        2,\n",
    "        \"C\",\n",
    "    ),\n",
    "    (\n",
    "        4,\n",
    "        [\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "        ],\n",
    "        4,\n",
    "        \"E\",\n",
    "        1,\n",
    "        \"B\",\n",
    "    ),\n",
    "    (\n",
    "        5,\n",
    "        [\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "        ],\n",
    "        5,\n",
    "        \"F\",\n",
    "        1,\n",
    "        \"B\",\n",
    "    ),\n",
    "    (\n",
    "        6,\n",
    "        [\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "        ],\n",
    "        6,\n",
    "        \"G\",\n",
    "        2,\n",
    "        \"C\",\n",
    "    ),\n",
    "    (\n",
    "        7,\n",
    "        [\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "        ],\n",
    "        7,\n",
    "        \"H\",\n",
    "        1,\n",
    "        \"B\",\n",
    "    ),\n",
    "    (\n",
    "        8,\n",
    "        [\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "        ],\n",
    "        8,\n",
    "        \"I\",\n",
    "        3,\n",
    "        \"I\",\n",
    "    ),\n",
    "    (\n",
    "        9,\n",
    "        [\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "        ],\n",
    "        9,\n",
    "        \"J\",\n",
    "        4,\n",
    "        \"J\",\n",
    "    ),\n",
    "    (\n",
    "        10,\n",
    "        [\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "        ],\n",
    "        10,\n",
    "        \"K\",\n",
    "        5,\n",
    "        \"K\",\n",
    "    ),\n",
    "    (\n",
    "        11,\n",
    "        [\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "        ],\n",
    "        11,\n",
    "        \"L\",\n",
    "        2,\n",
    "        \"C\",\n",
    "    ),\n",
    "    (\n",
    "        12,\n",
    "        [\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "        ],\n",
    "        12,\n",
    "        \"M\",\n",
    "        6,\n",
    "        \"M\",\n",
    "    ),\n",
    "    (\n",
    "        13,\n",
    "        [\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "        ],\n",
    "        13,\n",
    "        \"N\",\n",
    "        6,\n",
    "        \"M\",\n",
    "    ),\n",
    "    (\n",
    "        14,\n",
    "        [\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "        ],\n",
    "        14,\n",
    "        \"O\",\n",
    "        2,\n",
    "        \"C\",\n",
    "    ),\n",
    "    (\n",
    "        15,\n",
    "        [\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "        ],\n",
    "        15,\n",
    "        \"P\",\n",
    "        1,\n",
    "        \"B\",\n",
    "    ),\n",
    "    (\n",
    "        16,\n",
    "        [\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "        ],\n",
    "        16,\n",
    "        \"Q\",\n",
    "        2,\n",
    "        \"C\",\n",
    "    ),\n",
    "    (\n",
    "        17,\n",
    "        [\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "        ],\n",
    "        17,\n",
    "        \"R\",\n",
    "        1,\n",
    "        \"B\",\n",
    "    ),\n",
    "    (\n",
    "        18,\n",
    "        [\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "        ],\n",
    "        18,\n",
    "        \"S\",\n",
    "        7,\n",
    "        \"S\",\n",
    "    ),\n",
    "    (\n",
    "        19,\n",
    "        [\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "        ],\n",
    "        19,\n",
    "        \"T\",\n",
    "        3,\n",
    "        \"I\",\n",
    "    ),\n",
    "    (\n",
    "        20,\n",
    "        [\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "        ],\n",
    "        20,\n",
    "        \"U\",\n",
    "        2,\n",
    "        \"C\",\n",
    "    ),\n",
    "    (\n",
    "        21,\n",
    "        [\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "        ],\n",
    "        21,\n",
    "        \"V\",\n",
    "        6,\n",
    "        \"M\",\n",
    "    ),\n",
    "    (\n",
    "        22,\n",
    "        [\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "        ],\n",
    "        22,\n",
    "        \"W\",\n",
    "        6,\n",
    "        \"M\",\n",
    "    ),\n",
    "    (\n",
    "        23,\n",
    "        [\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "        ],\n",
    "        23,\n",
    "        \"X\",\n",
    "        6,\n",
    "        \"M\",\n",
    "    ),\n",
    "    (\n",
    "        24,\n",
    "        [\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "        ],\n",
    "        24,\n",
    "        \"Y\",\n",
    "        6,\n",
    "        \"M\",\n",
    "    ),\n",
    "    (\n",
    "        25,\n",
    "        [\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "        ],\n",
    "        25,\n",
    "        \"Z\",\n",
    "        6,\n",
    "        \"M\",\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_B37VsqUDL8Y",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# naive\n",
    "(\n",
    "    1,\n",
    "    [\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "    ],\n",
    "    1,\n",
    "    \"A\",\n",
    "    7,\n",
    "    \"A\",\n",
    "),\n",
    "(\n",
    "    2,\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "    ],\n",
    "    2,\n",
    "    \"B\",\n",
    "    2,\n",
    "    \"B\",\n",
    "),\n",
    "(\n",
    "    3,\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "    ],\n",
    "    3,\n",
    "    \"C\",\n",
    "    2,\n",
    "    \"B\",\n",
    "),\n",
    "(\n",
    "    4,\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "    ],\n",
    "    4,\n",
    "    \"D\",\n",
    "    2,\n",
    "    \"B\",\n",
    "),\n",
    "(\n",
    "    5,\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "    ],\n",
    "    5,\n",
    "    \"E\",\n",
    "    2,\n",
    "    \"B\",\n",
    "),\n",
    "(\n",
    "    6,\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "    ],\n",
    "    6,\n",
    "    \"F\",\n",
    "    3,\n",
    "    \"F\",\n",
    "),\n",
    "(\n",
    "    7,\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "    ],\n",
    "    7,\n",
    "    \"G\",\n",
    "    2,\n",
    "    \"B\",\n",
    "),\n",
    "(\n",
    "    8,\n",
    "    [\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "    ],\n",
    "    8,\n",
    "    \"H\",\n",
    "    0,\n",
    "    \"H\",\n",
    "),\n",
    "(\n",
    "    9,\n",
    "    [\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "    ],\n",
    "    9,\n",
    "    \"I\",\n",
    "    4,\n",
    "    \"I\",\n",
    "),\n",
    "(\n",
    "    10,\n",
    "    [\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "    ],\n",
    "    10,\n",
    "    \"J\",\n",
    "    5,\n",
    "    \"J\",\n",
    "),\n",
    "(\n",
    "    11,\n",
    "    [\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "    ],\n",
    "    11,\n",
    "    \"K\",\n",
    "    1,\n",
    "    \"K\",\n",
    "),\n",
    "(\n",
    "    12,\n",
    "    [\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "    ],\n",
    "    12,\n",
    "    \"L\",\n",
    "    1,\n",
    "    \"K\",\n",
    "),\n",
    "(\n",
    "    13,\n",
    "    [\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "    ],\n",
    "    13,\n",
    "    \"M\",\n",
    "    0,\n",
    "    \"H\",\n",
    "),\n",
    "(\n",
    "    14,\n",
    "    [\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "    ],\n",
    "    14,\n",
    "    \"N\",\n",
    "    0,\n",
    "    \"H\",\n",
    "),\n",
    "(\n",
    "    15,\n",
    "    [\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "    ],\n",
    "    15,\n",
    "    \"O\",\n",
    "    2,\n",
    "    \"B\",\n",
    "),\n",
    "(\n",
    "    16,\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "    ],\n",
    "    16,\n",
    "    \"P\",\n",
    "    3,\n",
    "    \"F\",\n",
    "),\n",
    "(\n",
    "    17,\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "    ],\n",
    "    17,\n",
    "    \"Q\",\n",
    "    2,\n",
    "    \"B\",\n",
    "),\n",
    "(\n",
    "    18,\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "    ],\n",
    "    18,\n",
    "    \"R\",\n",
    "    3,\n",
    "    \"F\",\n",
    "),\n",
    "(\n",
    "    19,\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "    ],\n",
    "    19,\n",
    "    \"S\",\n",
    "    2,\n",
    "    \"B\",\n",
    "),\n",
    "(\n",
    "    20,\n",
    "    [\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "    ],\n",
    "    20,\n",
    "    \"T\",\n",
    "    4,\n",
    "    \"I\",\n",
    "),\n",
    "(\n",
    "    21,\n",
    "    [\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "    ],\n",
    "    21,\n",
    "    \"U\",\n",
    "    1,\n",
    "    \"K\",\n",
    "),\n",
    "(\n",
    "    22,\n",
    "    [\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "    ],\n",
    "    22,\n",
    "    \"V\",\n",
    "    6,\n",
    "    \"V\",\n",
    "),\n",
    "(\n",
    "    23,\n",
    "    [\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "    ],\n",
    "    23,\n",
    "    \"W\",\n",
    "    0,\n",
    "    \"H\",\n",
    "),\n",
    "(\n",
    "    24,\n",
    "    [\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "    ],\n",
    "    24,\n",
    "    \"X\",\n",
    "    5,\n",
    "    \"J\",\n",
    "),\n",
    "(\n",
    "    25,\n",
    "    [\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "    ],\n",
    "    25,\n",
    "    \"Y\",\n",
    "    5,\n",
    "    \"J\",\n",
    "),\n",
    "(\n",
    "    26,\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "    ],\n",
    "    26,\n",
    "    \"Z\",\n",
    "    2,\n",
    "    \"B\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f3twzUu1WeIE"
   },
   "source": [
    "### Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1589335107008,
     "user": {
      "displayName": "Chris Rico",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHHfN9cEcyW0UKEYRqrJJRVc7VtUuJszJ9nM8=s64",
      "userId": "02883936081336753861"
     },
     "user_tz": 420
    },
    "id": "YgSCP9Osw1ss",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "606869df-7c2d-45e3-e608-fbcd3e426522",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:5000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 612,
     "status": "ok",
     "timestamp": 1589335112455,
     "user": {
      "displayName": "Chris Rico",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHHfN9cEcyW0UKEYRqrJJRVc7VtUuJszJ9nM8=s64",
      "userId": "02883936081336753861"
     },
     "user_tz": 420
    },
    "id": "OsPMw_v1u-wt",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "12f834f1-7642-4625-e9ce-df02cb066e68",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ################################################################################################\n",
    "#\n",
    "#\n",
    "#  9x9 Module 4\n",
    "#\n",
    "#\n",
    "# ################################################################################################\n",
    "import os\n",
    "import random\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "\n",
    "# We want to use the exp function (e to the x); it's part of our transfer function definition\n",
    "from math import exp\n",
    "\n",
    "# Biting the bullet and starting to use NumPy for arrays\n",
    "import numpy as np\n",
    "\n",
    "# So we can make a separate list from an initial one\n",
    "import copy\n",
    "\n",
    "# import packages for heatmap associated generation\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.colors import ListedColormap\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"none\"\n",
    "%matplotlib inline\n",
    "\n",
    "# For pretty-printing the arrays\n",
    "np.set_printoptions(precision=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GWzvmV37Wjk6"
   },
   "source": [
    "### Training Data List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZmhBDB1R8SmI",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "  # Note: Nine possible output classes: 0 .. 8 trainingDataListXX [4] \n",
    "  trainingDataList = [\n",
    "        ( 0, [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1], 0, 'A', 7, 'A' ),\n",
    "        ( 1, [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], 1, 'B', 2, 'B' ),\n",
    "        ( 2, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], 2, 'C', 2, 'B' ),\n",
    "        ( 3, [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], 3, 'D', 2, 'B' ),\n",
    "        ( 4, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], 4, 'E', 2, 'B' ),\n",
    "        ( 5, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 5, 'F', 3, 'F' ),\n",
    "        ( 6, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 6, 'G', 2, 'B' ),\n",
    "        ( 7, [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1], 7, 'H', 0, 'H' ),\n",
    "        ( 8, [0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0], 8, 'I', 4, 'I' ),\n",
    "        ( 9, [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], 9, 'J', 5, 'J' ),\n",
    "        ( 10, [1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0], 10, 'K', 1, 'K' ),\n",
    "        ( 11, [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], 11, 'L', 1, 'K' ),\n",
    "        ( 12, [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1], 12, 'M', 0, 'H' ),\n",
    "        ( 13, [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1], 13, 'N', 0, 'H' ),\n",
    "        ( 14, [0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0], 14, 'O', 2, 'B' ),\n",
    "        ( 15, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 15, 'P', 3, 'F' ),\n",
    "        ( 16, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 16, 'Q', 2, 'B' ),\n",
    "        ( 17, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], 17, 'R', 3, 'F' ),\n",
    "        ( 18, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 18, 'S', 2, 'B' ),\n",
    "        ( 19, [0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 19, 'T', 4, 'I' ),\n",
    "        ( 20, [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 20, 'U', 1, 'K' ),\n",
    "        ( 21, [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 21, 'V', 6, 'V' ),\n",
    "        ( 22, [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0], 22, 'W', 0, 'H' ),\n",
    "        ( 23, [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], 23, 'X', 5, 'J' ),\n",
    "        ( 24, [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 24, 'Y', 5, 'J' ),\n",
    "        ( 25, [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], 25, 'Z', 2, 'B' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hysLDgQwWMFV"
   },
   "source": [
    "### Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_6KyNbDBvL71",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# After computing final SSEs, etc., store all the weights to files (four different files)\n",
    "####################################################################################################\n",
    "def saveWeights(\n",
    "    inputArrayLength,\n",
    "    hiddenArrayLength,\n",
    "    outputArrayLength,\n",
    "    wWeightArray,\n",
    "    vWeightArray,\n",
    "    biasHiddenWeightArray,\n",
    "    biasOutputWeightArray,\n",
    "):\n",
    "    # Create lists of the connection weights; one for the input-to-hidden, another for the hidden-to-output\n",
    "    wWeightList = list()\n",
    "    numUpperNodes = hiddenArrayLength\n",
    "    numLowerNodes = inputArrayLength\n",
    "    for row in range(numUpperNodes):  #  Number of rows in weightMatrix\n",
    "        # For an input-to-hidden weight matrix, the rows correspond to the number of hidden nodes\n",
    "        #    and the columns correspond to the number of input nodes.\n",
    "        #    This creates an HxI matrix, which can be multiplied by the input matrix (expressed as a column)\n",
    "        # Similarly, for a hidden-to-output matrix, the rows correspond to the number of output nodes.\n",
    "        for col in range(numLowerNodes):  # number of columns in matrix 2\n",
    "            localWeight = wWeightArray[row, col]\n",
    "            wWeightList.append(localWeight)\n",
    "\n",
    "    #    print wWeightList\n",
    "\n",
    "    # Write the input-to-hidden connection weights to a file\n",
    "\n",
    "    wWeightFile = open(\"./datafiles/GB1wWeightFile.csv\", \"w\")\n",
    "\n",
    "    for item in wWeightList:\n",
    "        wWeightFile.write(\"%s\\n\" % item)\n",
    "    wWeightFile.close()\n",
    "\n",
    "    # do the same for the hidden to output weights\n",
    "\n",
    "    vWeightList = list()\n",
    "    numUpperNodes = outputArrayLength\n",
    "    numLowerNodes = hiddenArrayLength\n",
    "    for row in range(numUpperNodes):  #  Number of rows in weightMatrix\n",
    "        # For an input-to-hidden weight matrix, the rows correspond to the number of hidden nodes\n",
    "        #    and the columns correspond to the number of input nodes.\n",
    "        #    This creates an HxI matrix, which can be multiplied by the input matrix (expressed as a column)\n",
    "        # Similarly, for a hidden-to-output matrix, the rows correspond to the number of output nodes.\n",
    "        for col in range(numLowerNodes):  # number of columns in matrix 2\n",
    "            localWeight = vWeightArray[row, col]\n",
    "            vWeightList.append(localWeight)\n",
    "\n",
    "    #    print vWeightList\n",
    "\n",
    "    # Write the hidden-to-output connection weights to a file\n",
    "\n",
    "    vWeightFile = open(\"./datafiles/GB1vWeightFile.csv\", \"w\")\n",
    "\n",
    "    for item in vWeightList:\n",
    "        vWeightFile.write(\"%s\\n\" % item)\n",
    "\n",
    "    vWeightFile.close()\n",
    "\n",
    "    # Do the same thing for the two sets of bias weights\n",
    "\n",
    "    # Start with the hidden node bias weights\n",
    "\n",
    "    # Create a list storing the array values for the hidden node bias weights\n",
    "    wBiasWeightList = list()\n",
    "    for node in range(hiddenArrayLength):  #  Number of hidden bias nodes\n",
    "        localBiasWeight = biasHiddenWeightArray[node]\n",
    "        wBiasWeightList.append(localBiasWeight)\n",
    "\n",
    "    # Write the hidden node bias weights to a file\n",
    "\n",
    "    wBiasWeightFile = open(\"./datafiles/GB1wBiasWeightFile.csv\", \"w\")\n",
    "\n",
    "    for item in wBiasWeightList:\n",
    "        wBiasWeightFile.write(\"%s\\n\" % item)\n",
    "    wBiasWeightFile.close()\n",
    "\n",
    "    # Repeat the process with the output node bias weights\n",
    "\n",
    "    # Create a list storing the array values for the output node bias weights\n",
    "    vBiasWeightList = list()\n",
    "    for node in range(outputArrayLength):  #  Number of output nodes\n",
    "        localBiasWeight = biasOutputWeightArray[node]\n",
    "        vBiasWeightList.append(localBiasWeight)\n",
    "\n",
    "    # Write the output node bias weights to a file\n",
    "\n",
    "    vBiasWeightFile = open(\"./datafiles/GB1vBiasWeightFile.csv\", \"w\")\n",
    "\n",
    "    for item in vBiasWeightList:\n",
    "        vBiasWeightFile.write(\"%s\\n\" % item)\n",
    "    vBiasWeightFile.close()\n",
    "\n",
    "    print(\" Completed training and storing connection weights to files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sWDoWFRSWFp7"
   },
   "source": [
    "### Worker functions and Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-GRFBThu-wv",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# Function to return a trainingDataList\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "#   - First 81 values will be the 9x9 pixel-grid representation of the letter\n",
    "#       represented as a 1-D array (0 or 1 for each)\n",
    "#   - 82nd value will be the output class (0 .. totalClasses - 1)\n",
    "#   - 83rd value will be the string associated with that class, e.g., 'X'\n",
    "\n",
    "\n",
    "def obtainSelectedAlphabetTrainingValues(dataSet):\n",
    "    return trainingDataList[dataSet]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gs-qAeB_u-wy",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# Function to initialize a specific connection weight with a randomly-generated number between 0 & 1\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "def obtainRandomAlphabetTrainingValues():\n",
    "    dataSet = random.randint(0, len(trainingDataList))\n",
    "    return trainingDataList[dataSet]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z3Puvdbqw1sw",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# We will randomly define initial values for connection weights, and also randomly select\n",
    "#   which training data that we will use for a given run.\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# This is a tutorial program, designed for those who are learning Python, and specifically using\n",
    "#   Python for neural networks applications\n",
    "#\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# Code Map: List of Procedures / Functions\n",
    "# - welcome\n",
    "#\n",
    "# == set of basic functions ==\n",
    "# - computeTransferFnctn\n",
    "# - computeTransferFnctnDeriv\n",
    "# - matrixDotProduct\n",
    "#\n",
    "# == identify crucial parameters (these can be changed by the user)\n",
    "#    obtainNeuralNetworkSizeSpecs\n",
    "#\n",
    "#    -- initializeWeight\n",
    "# - initializeWeightArray\n",
    "# - initializeBiasWeightArray\n",
    "#\n",
    "# == obtain the training data (two possible routes; user selection & random)\n",
    "# - obtainSelectedAlphabetTrainingValues\n",
    "# - obtainRandomAlphabetTrainingValues\n",
    "#\n",
    "# == the feedforward modules\n",
    "#   -- ComputeSingleFeedforwardPassFirstStep\n",
    "#   -- ComputeSingleFeedforwardPassSecondStep\n",
    "# - ComputeOutputsAcrossAllTrainingData\n",
    "#\n",
    "# == the backpropagation training modules\n",
    "# - backpropagateOutputToHidden\n",
    "# - backpropagateBiasOutputWeights\n",
    "# - backpropagateHiddenToInput\n",
    "# - backpropagateBiasHiddenWeights\n",
    "# - main\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# Procedure to welcome the user and identify the code\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "def welcome():\n",
    "\n",
    "    print()\n",
    "    print(\n",
    "        \"******************************************************************************\"\n",
    "    )\n",
    "    print()\n",
    "    print(\"Welcome to the Multilayer Perceptron Neural Network\")\n",
    "    print(\"trained using the backpropagation method.\")\n",
    "    print(\"Version 0.4, 03/05/2017, A.J. Maren\")\n",
    "    print(\n",
    "        \"For comments, questions, or bug-fixes, contact: alianna.maren@northwestern.edu\"\n",
    "    )\n",
    "    print()\n",
    "    print(\"This program learns to distinguish between broad classes of capital letters\")\n",
    "    print(\"It allows users to examine the hidden weights to identify learned features\")\n",
    "    print()\n",
    "    print(\n",
    "        \"******************************************************************************\"\n",
    "    )\n",
    "    print()\n",
    "    return ()\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# A collection of worker-functions, designed to do specific small tasks\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "# ------------------------------------------------------#\n",
    "\n",
    "# Compute neuron activation using sigmoid transfer function\n",
    "def computeTransferFnctn(summedNeuronInput, alpha):\n",
    "    activation = 1.0 / (1.0 + exp(-alpha * summedNeuronInput))\n",
    "    return activation\n",
    "\n",
    "\n",
    "# ------------------------------------------------------#\n",
    "\n",
    "# Compute derivative of transfer function\n",
    "def computeTransferFnctnDeriv(NeuronOutput, alpha):\n",
    "    return alpha * NeuronOutput * (1.0 - NeuronOutput)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------#\n",
    "def matrixDotProduct(matrx1, matrx2):\n",
    "    dotProduct = np.dot(matrx1, matrx2)\n",
    "\n",
    "    return dotProduct\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# Function to obtain the neural network size specifications\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "def obtainNeuralNetworkSizeSpecs(num_hidden, num_output):\n",
    "\n",
    "    # This procedure operates as a function, as it returns a single value (which really is a list of\n",
    "    #    three values). It is called directly from 'main.'\n",
    "    #\n",
    "    # This procedure allows the user to specify the size of the input (I), hidden (H),\n",
    "    #    and output (O) layers.\n",
    "    # These values will be stored in a list, the arraySizeList.\n",
    "    # This list will be used to specify the sizes of two different weight arrays:\n",
    "    #   - wWeights; the Input-to-Hidden array, and\n",
    "    #   - vWeights; the Hidden-to-Output array.\n",
    "    # However, even though we're calling this procedure, we will still hard-code the array sizes for now.\n",
    "\n",
    "    numInputNodes = 81\n",
    "    numHiddenNodes = num_hidden\n",
    "    numOutputNodes = num_output\n",
    "    print()\n",
    "    print(\"  The number of nodes at each level are:\")\n",
    "    print(\"    Input: 9x9 (square array)\")\n",
    "    print(\"    Hidden: \", numHiddenNodes)\n",
    "    print(\"    Output: \", numOutputNodes)\n",
    "\n",
    "    # We create a list containing the crucial SIZES for the connection weight arrays\n",
    "    arraySizeList = (numInputNodes, numHiddenNodes, numOutputNodes)\n",
    "\n",
    "    # We return this list to the calling procedure, 'main'.\n",
    "    return arraySizeList\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "#\n",
    "# Function to initialize a specific connection weight with a randomly-generated number between 0 & 1\n",
    "#\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "def InitializeWeight():\n",
    "\n",
    "    randomNum = random.random()\n",
    "    weight = 1 - 2 * randomNum\n",
    "    #    print weight\n",
    "\n",
    "    return weight\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# Function to initialize the node-to-node connection weight arrays\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "def initializeWeightArray(weightArraySizeList):\n",
    "\n",
    "    # This procedure is also called directly from 'main.'\n",
    "    #\n",
    "    # This procedure takes in the two parameters, the number of nodes on the bottom (of any two layers),\n",
    "    #   and the number of nodes in the layer just above it.\n",
    "    #   It will use these two sizes to create a weight array.\n",
    "    # The weights will initially be assigned random values here, and\n",
    "    #   this array is passed back to the 'main' procedure.\n",
    "\n",
    "    numLowerNodes = weightArraySizeList[0]\n",
    "    numUpperNodes = weightArraySizeList[1]\n",
    "\n",
    "    #    print ' '\n",
    "    #    print ' inside procedure initializeWeightArray'\n",
    "    #    print ' the number of lower nodes is', numLowerNodes\n",
    "    #    print ' the number of upper nodes is', numUpperNodes\n",
    "    #\n",
    "    # Initialize the weight variables with random weights\n",
    "    weightArray = np.zeros(\n",
    "        (numUpperNodes, numLowerNodes)\n",
    "    )  # iniitalize the weight matrix with 0's\n",
    "    for row in range(numUpperNodes):  #  Number of rows in weightMatrix\n",
    "        # For an input-to-hidden weight matrix, the rows correspond to the number of hidden nodes\n",
    "        #    and the columns correspond to the number of input nodes.\n",
    "        #    This creates an HxI matrix, which can be multiplied by the input matrix (expressed as a column)\n",
    "        # Similarly, for a hidden-to-output matrix, the rows correspond to the number of output nodes.\n",
    "        for col in range(numLowerNodes):  # number of columns in matrix 2\n",
    "            weightArray[row, col] = InitializeWeight()\n",
    "\n",
    "    #    print weightArray\n",
    "\n",
    "    # We return the array to the calling procedure, 'main'.\n",
    "    return weightArray\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# Function to initialize the bias weight arrays\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "def initializeBiasWeightArray(numBiasNodes):\n",
    "\n",
    "    # This procedure is also called directly from 'main.'\n",
    "\n",
    "    # Initialize the bias weight variables with random weights\n",
    "    biasWeightArray = np.zeros(numBiasNodes)  # iniitalize the weight matrix with 0's\n",
    "    for node in range(numBiasNodes):  #  Number of nodes in bias weight set\n",
    "        biasWeightArray[node] = InitializeWeight()\n",
    "\n",
    "    # Print the entire weights array.\n",
    "    #    print biasWeightArray\n",
    "\n",
    "    # We return the array to the calling procedure, 'main'.\n",
    "    return biasWeightArray\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# Perform a single feedforward pass\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "#\n",
    "# Function to initialize a specific connection weight with a randomly-generated number between 0 & 1\n",
    "#\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "def ComputeSingleFeedforwardPassFirstStep(\n",
    "    alpha, inputDataList, wWeightArray, biasHiddenWeightArray\n",
    "):\n",
    "\n",
    "    # iniitalize the sum of inputs into the hidden array with 0's\n",
    "    sumIntoHiddenArray = np.zeros(hiddenArrayLength)\n",
    "    hiddenArray = np.zeros(hiddenArrayLength)\n",
    "\n",
    "    sumIntoHiddenArray = matrixDotProduct(wWeightArray, inputDataList)\n",
    "\n",
    "    for node in range(hiddenArrayLength):  #  Number of hidden nodes\n",
    "        hiddenNodeSumInput = sumIntoHiddenArray[node] + biasHiddenWeightArray[node]\n",
    "        hiddenArray[node] = computeTransferFnctn(hiddenNodeSumInput, alpha)\n",
    "\n",
    "    #    print ' '\n",
    "    #    print 'Back in ComputeSingleFeedforwardPass'\n",
    "    #    print 'The activations for the hidden nodes are:'\n",
    "    #    print '  Hidden0 = %.4f' % hiddenActivation0, 'Hidden1 = %.4f' % hiddenActivation1\n",
    "\n",
    "    return hiddenArray\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "#\n",
    "# Function to compute the output node activations, given the hidden node activations, the hidden-to\n",
    "#   output connection weights, and the output bias weights.\n",
    "# Function returns the array of output node activations.\n",
    "#\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "def ComputeSingleFeedforwardPassSecondStep(\n",
    "    alpha, hiddenArray, vWeightArray, biasOutputWeightArray\n",
    "):\n",
    "\n",
    "    # initialize the sum of inputs into the hidden array with 0's\n",
    "    sumIntoOutputArray = np.zeros(hiddenArrayLength)\n",
    "    outputArray = np.zeros(outputArrayLength)\n",
    "\n",
    "    sumIntoOutputArray = matrixDotProduct(vWeightArray, hiddenArray)\n",
    "\n",
    "    for node in range(outputArrayLength):  #  Number of hidden nodes\n",
    "        outputNodeSumInput = sumIntoOutputArray[node] + biasOutputWeightArray[node]\n",
    "        outputArray[node] = computeTransferFnctn(outputNodeSumInput, alpha)\n",
    "\n",
    "    return outputArray\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "#\n",
    "# Procedure to compute the output node activations and determine errors across the entire training\n",
    "#  data set, and print results.\n",
    "#\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "def ComputeOutputsAcrossAllTrainingData(\n",
    "    alpha,\n",
    "    numTrainingDataSets,\n",
    "    wWeightArray,\n",
    "    biasHiddenWeightArray,\n",
    "    vWeightArray,\n",
    "    biasOutputWeightArray,\n",
    "    arraySizeList,\n",
    "):\n",
    "\n",
    "    selectedTrainingDataSet = 0\n",
    "\n",
    "    # ##################################################################\n",
    "    # code added 01/31/19\n",
    "    # lists to hold activations\n",
    "    # ##################################################################\n",
    "    hiddenNodeActivationsList = []\n",
    "    outputNodeActivationsList = []\n",
    "\n",
    "    trainingDesiredClass = []\n",
    "    trainingSelectedClass = []\n",
    "    trainingLetters = []\n",
    "    trainingSelectedEqDesired = []\n",
    "\n",
    "    while selectedTrainingDataSet < numTrainingDataSets:\n",
    "        print()\n",
    "        print(\" the selected Training Data Set is \", selectedTrainingDataSet)\n",
    "        trainingDataList = obtainSelectedAlphabetTrainingValues(selectedTrainingDataSet)\n",
    "\n",
    "        # Note: the trainingDataList is a list comprising several values:\n",
    "        #    - the 0th is the list number\n",
    "        #    - the 1st is the actual list of the input training values\n",
    "        #    - etc.\n",
    "\n",
    "        trainingDataInputList = trainingDataList[1]\n",
    "\n",
    "        inputDataList = []\n",
    "        for node in range(0, inputArrayLength):\n",
    "            trainingData = trainingDataInputList[node]\n",
    "            inputDataList.append(trainingData)\n",
    "\n",
    "        letterNum = trainingDataList[2]\n",
    "        letterChar = trainingDataList[3]\n",
    "        print()\n",
    "        print(\n",
    "            \"  Data Set Number\",\n",
    "            selectedTrainingDataSet,\n",
    "            \" for letter \",\n",
    "            letterChar,\n",
    "            \" with letter number \",\n",
    "            letterNum,\n",
    "        )\n",
    "\n",
    "        hiddenArray = ComputeSingleFeedforwardPassFirstStep(\n",
    "            alpha, inputDataList, wWeightArray, biasHiddenWeightArray\n",
    "        )\n",
    "\n",
    "        print()\n",
    "        print(\" The hidden node activations are: \")\n",
    "        print(hiddenArray)\n",
    "\n",
    "        outputArray = ComputeSingleFeedforwardPassSecondStep(\n",
    "            alpha, hiddenArray, vWeightArray, biasOutputWeightArray\n",
    "        )\n",
    "\n",
    "        print()\n",
    "        print(\" The output node activations are: \")\n",
    "        print(outputArray)\n",
    "\n",
    "        # ########################\n",
    "        # code added 01/31/19\n",
    "        # append activations\n",
    "        # ########################\n",
    "        hiddenNodeActivationsList.append(\n",
    "            [\n",
    "                letterChar,\n",
    "                letterNum,\n",
    "                trainingDataList[4],\n",
    "                \"\\n\".join([letterChar, trainingDataList[5]]),\n",
    "                hiddenArray,\n",
    "            ]\n",
    "        )\n",
    "        outputNodeActivationsList.append(\n",
    "            [\n",
    "                letterChar,\n",
    "                letterNum,\n",
    "                trainingDataList[4],\n",
    "                \"\\n\".join([letterChar, trainingDataList[5]]),\n",
    "                outputArray,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        desiredOutputArray = np.zeros(\n",
    "            outputArrayLength\n",
    "        )  # iniitalize the output array with 0's\n",
    "        desiredClass = trainingDataList[4]  # identify the desired class\n",
    "        desiredOutputArray[\n",
    "            desiredClass\n",
    "        ] = 1  # set the desired output for that class to 1\n",
    "\n",
    "        print()\n",
    "        print(\" The desired output array values are: \")\n",
    "        print(desiredOutputArray)\n",
    "\n",
    "        # Determine the error between actual and desired outputs\n",
    "        # Initialize the error array\n",
    "        errorArray = np.zeros(outputArrayLength)\n",
    "\n",
    "        newSSE = 0.0\n",
    "        for node in range(\n",
    "            outputArrayLength\n",
    "        ):  #  Number of nodes in output set (classes)\n",
    "            errorArray[node] = desiredOutputArray[node] - outputArray[node]\n",
    "            newSSE = newSSE + errorArray[node] * errorArray[node]\n",
    "\n",
    "        print()\n",
    "        print(\"The selected output class was %2.0f\" % np.argmax(outputArray))\n",
    "        print(\"The desired  output class was %2.0f\" % desiredClass)\n",
    "        trainingLetters.append(letterChar)\n",
    "        trainingDesiredClass.append(desiredClass)\n",
    "        trainingSelectedClass.append(np.argmax(outputArray))\n",
    "        if np.argmax(outputArray) == desiredClass:\n",
    "            trainingSelectedEqDesired.append(\"Y\")\n",
    "        else:\n",
    "            trainingSelectedEqDesired.append(\"N\")\n",
    "\n",
    "        print()\n",
    "        print(\" ' The error values are:\")\n",
    "        print(errorArray)\n",
    "\n",
    "        # Print the Summed Squared Error\n",
    "        print(\"New SSE = %.6f\" % newSSE)\n",
    "\n",
    "        selectedTrainingDataSet = selectedTrainingDataSet + 1\n",
    "\n",
    "    ##################################################################\n",
    "    # code added 10/19/19\n",
    "    # print summary of desired and selected output classes\n",
    "    # ##################################################################\n",
    "    print(\"\\n\\n\\n\\nDesired/Selected Output Classes\")\n",
    "    print(\n",
    "        \"========================================================================================\"\n",
    "    )\n",
    "    print(\n",
    "        \"========================================================================================\\n\"\n",
    "    )\n",
    "    dfResults = pd.DataFrame(\n",
    "        {\n",
    "            \"Letter\": trainingLetters,\n",
    "            \"Desired\": trainingDesiredClass,\n",
    "            \"Selected\": trainingSelectedClass,\n",
    "            \"Correct\": trainingSelectedEqDesired,\n",
    "        },\n",
    "        columns=[\"Letter\", \"Desired\", \"Selected\", \"Correct\"],\n",
    "    ).transpose()\n",
    "\n",
    "    pd.set_option(\"display.max_columns\", 500)\n",
    "    pd.set_option(\"display.width\", 1000)\n",
    "    pd.set_option(\"precision\", 5)\n",
    "\n",
    "    with pd.option_context(\n",
    "        \"display.max_rows\", None, \"display.max_columns\", dfResults.shape[1]\n",
    "    ):\n",
    "        print(dfResults)\n",
    "\n",
    "    numClassMatches = 0\n",
    "    for indxL in range(len(trainingDesiredClass)):\n",
    "        if trainingDesiredClass[indxL] == trainingSelectedClass[indxL]:\n",
    "            numClassMatches = numClassMatches + 1\n",
    "    print(\n",
    "        \"Percent Accuracy %4.2f\"\n",
    "        % ((numClassMatches / len(trainingDesiredClass)) * 100.0)\n",
    "    )\n",
    "    print(\n",
    "        \"========================================================================================\"\n",
    "    )\n",
    "    print(\n",
    "        \"========================================================================================\\n\"\n",
    "    )\n",
    "    sns.set(rc={\"figure.figsize\": (5.5, 4.0)})\n",
    "    fig, ax = plt.subplots()\n",
    "    dfCS = pd.DataFrame(\n",
    "        {\"Desired\": trainingDesiredClass, \"Selected\": trainingSelectedClass},\n",
    "        columns=[\"Desired\", \"Selected\"],\n",
    "    )\n",
    "    dfCT = pd.crosstab(dfCS[\"Desired\"], dfCS[\"Selected\"])\n",
    "    dfCT = (\n",
    "        dfCT.reindex(index=range(arraySizeList[2]), columns=range(arraySizeList[2]))\n",
    "        .fillna(0)\n",
    "        .astype(\"int\")\n",
    "    )\n",
    "    ax = sns.heatmap(\n",
    "        dfCT, cmap=\"YlOrRd\", annot=True, linewidths=0.1, linecolor=\"white\", fmt=\"d\"\n",
    "    )\n",
    "    ax.set_title(\"Classes Desired/Selected\")\n",
    "    plt.show()\n",
    "\n",
    "    # ##################################################################\n",
    "    # code added 01/31/19\n",
    "    # visualize activations from output layer in heat map\n",
    "    # ##################################################################\n",
    "    print(\"\\n\\nhiddenNodeActivationsList L-{letter} C-{class}\")\n",
    "    print(\"==============================================\")\n",
    "    print(\"==============================================\\n\")\n",
    "    df = pd.DataFrame([lst[4] for lst in hiddenNodeActivationsList])\n",
    "    df = df.transpose()\n",
    "    df.columns = (x[3] for x in hiddenNodeActivationsList)\n",
    "    df.columns = \"L-\" + df.columns.str[0:1] + \" C-\" + df.columns.str[2:3]\n",
    "    df = df.transpose()\n",
    "    display(df)\n",
    "\n",
    "    # hidden nodes heatmap\n",
    "    print(\"\\n\\n\\n\\n\\n\")\n",
    "    ax = sns.heatmap(df)\n",
    "    ax.set_title(\"Hidden Node Activations\\nL-{letter} C-{class}\")\n",
    "    ax.set_xlabel(\"Node\")\n",
    "    ax.set_ylabel(\"L-{Letter} C-{Class}\")\n",
    "    plt.show()\n",
    "\n",
    "    # hidden nodes clustermap with row and column dendrogram\n",
    "    # print(\"\\n\\n\\n\\n\\n\")\n",
    "    # ax = sns.clustermap(df,cmap='YlOrRd',annot=False,linewidths=0.1,linecolor='white')\n",
    "    # ax.fig.suptitle('Hidden Node Activations\\nClustered by Node and Letter\\nL-{letter} C-{class}')\n",
    "    # plt.show()\n",
    "\n",
    "    # hidden nodes clustermap with column dendrogram\n",
    "    # print(\"\\n\\n\\n\\n\\n\")\n",
    "    # ax = sns.clustermap(df,cmap='YlOrRd',annot=False,linewidths=0.1,linecolor='white',row_cluster=False)\n",
    "    # ax.fig.suptitle('Hidden Node Activations\\nClustered Letter\\nL-{letter} C-{class}')\n",
    "    # plt.show()\n",
    "\n",
    "    return hiddenNodeActivationsList\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "# **************************************************************************************************#\n",
    "####################################################################################################\n",
    "#\n",
    "#   Backpropagation Section\n",
    "#\n",
    "####################################################################################################\n",
    "# **************************************************************************************************#\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# Backpropagate weight changes onto the hidden-to-output connection weights\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "def backpropagateOutputToHidden(\n",
    "    alpha, eta, arraySizeList, errorArray, outputArray, hiddenArray, vWeightArray\n",
    "):\n",
    "\n",
    "    # The first step here applies a backpropagation-based weight change to the hidden-to-output wts v.\n",
    "    # Core equation for the first part of backpropagation:\n",
    "    # d(SSE)/dv(h,o) = -alpha*Error*F(1-F)*Hidden(h)\n",
    "    # where:\n",
    "    # -- SSE = sum of squared errors, and only the error associated with a given output node counts\n",
    "    # -- v(h,o) is the connection weight v between the hidden node h and the output node o\n",
    "    # -- alpha is the scaling term within the transfer function, often set to 1\n",
    "    # ---- (this is included in transfFuncDeriv)\n",
    "    # -- Error = Error(o) or error at the output node o; = Desired(o) - Actual(o)\n",
    "    # -- F = transfer function, here using the sigmoid transfer function\n",
    "    # -- Hidden(h) = the output of hidden node h.\n",
    "\n",
    "    # We will DECREMENT the connection weight v by a small amount proportional to the derivative eqn\n",
    "    #   of the SSE w/r/t the weight v.\n",
    "    # This means, since there is a minus sign in that derivative, that we will add a small amount.\n",
    "    # (Decrementing is -, applied to a (-), which yields a positive.)\n",
    "\n",
    "    # For the actual derivation of this equation with MATCHING VARIABLE NAMES (easy to understand),\n",
    "    #   please consult: Brain-Based Computing, by AJ Maren (under development, Jan., 2017). Chpt. X.\n",
    "    #   (Meaning: exact chapter is still TBD.)\n",
    "    # For the latest updates, etc., please visit: www.aliannajmaren.com\n",
    "\n",
    "    # Unpack array lengths\n",
    "    hiddenArrayLength = arraySizeList[1]\n",
    "    outputArrayLength = arraySizeList[2]\n",
    "\n",
    "    transferFuncDerivArray = np.zeros(\n",
    "        outputArrayLength\n",
    "    )  # iniitalize an array for the transfer function\n",
    "\n",
    "    for node in range(outputArrayLength):  #  Number of hidden nodes\n",
    "        transferFuncDerivArray[node] = computeTransferFnctnDeriv(\n",
    "            outputArray[node], alpha\n",
    "        )\n",
    "\n",
    "    # Note: the parameter 'alpha' in the transfer function shows up in the transfer function derivative\n",
    "    #   and so is not included explicitly in the equations for the deltas in the connection weights\n",
    "    #    print ' '\n",
    "    #    print ' The transfer function derivative is: '\n",
    "    #    print transferFuncDerivArray\n",
    "\n",
    "    deltaVWtArray = np.zeros(\n",
    "        (outputArrayLength, hiddenArrayLength)\n",
    "    )  # initialize an array for the deltas\n",
    "    newVWeightArray = np.zeros(\n",
    "        (outputArrayLength, hiddenArrayLength)\n",
    "    )  # initialize an array for the new hidden weights\n",
    "\n",
    "    for row in range(outputArrayLength):  #  Number of rows in weightMatrix\n",
    "        # For an input-to-hidden weight matrix, the rows correspond to the number of hidden nodes,\n",
    "        #    and the columns correspond to the number of input nodes.\n",
    "        #    This creates an HxI matrix, which can be multiplied by the input node array (expressed as a column).\n",
    "        # Similarly, for a hidden-to-output matrix, the rows correspond to the number of output nodes,\n",
    "        #    and the columns correspond to the number of hidden nodes,\n",
    "        #    which can be multiplied by the hidden node array (expressed as a column).\n",
    "        for col in range(hiddenArrayLength):  # number of columns in weightMatrix\n",
    "            partialSSE_w_V_Wt = (\n",
    "                -errorArray[row] * transferFuncDerivArray[row] * hiddenArray[col]\n",
    "            )\n",
    "            deltaVWtArray[row, col] = -eta * partialSSE_w_V_Wt\n",
    "            newVWeightArray[row, col] = vWeightArray[row, col] + deltaVWtArray[row, col]\n",
    "\n",
    "    #    print ' '\n",
    "    #    print ' The previous hidden-to-output connection weights are: '\n",
    "    #    print vWeightArray\n",
    "    #    print ' '\n",
    "    #    print ' The new hidden-to-output connection weights are: '\n",
    "    #    print newVWeightArray\n",
    "\n",
    "    #    PrintAndTraceBackpropagateOutputToHidden (alpha, nu, errorList, actualAllNodesOutputList,\n",
    "    #    transFuncDerivList, deltaVWtArray, vWeightArray, newHiddenWeightArray)\n",
    "\n",
    "    return newVWeightArray\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# Backpropagate weight changes onto the bias-to-output connection weights\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "def backpropagateBiasOutputWeights(\n",
    "    alpha, eta, arraySizeList, errorArray, outputArray, biasOutputWeightArray\n",
    "):\n",
    "\n",
    "    # The first step here applies a backpropagation-based weight change to the hidden-to-output wts v.\n",
    "    # Core equation for the first part of backpropagation:\n",
    "    # d(SSE)/dv(h,o) = -alpha*Error*F(1-F)*Hidden(h)\n",
    "    # where:\n",
    "    # -- SSE = sum of squared errors, and only the error associated with a given output node counts\n",
    "    # -- v(h,o) is the connection weight v between the hidden node h and the output node o\n",
    "    # -- alpha is the scaling term within the transfer function, often set to 1\n",
    "    # ---- (this is included in transfFuncDeriv)\n",
    "    # -- Error = Error(o) or error at the output node o; = Desired(o) - Actual(o)\n",
    "    # -- F = transfer function, here using the sigmoid transfer function\n",
    "    # -- Hidden(h) = the output of hidden node h.\n",
    "\n",
    "    # Note that the training rate parameter is assigned in main; Greek letter \"eta,\" looks like n,\n",
    "    #   scales amount of change to connection weight\n",
    "\n",
    "    # We will DECREMENT the connection weight biasOutput by a small amount proportional to the derivative eqn\n",
    "    #   of the SSE w/r/t the weight biasOutput(o).\n",
    "    # This means, since there is a minus sign in that derivative, that we will add a small amount.\n",
    "    # (Decrementing is -, applied to a (-), which yields a positive.)\n",
    "\n",
    "    # For the actual derivation of this equation with MATCHING VARIABLE NAMES (easy to understand),\n",
    "    #   please consult: Brain-Based Computing, by AJ Maren (under development, Jan., 2017). Chpt. X.\n",
    "    #   (Meaning: exact chapter is still TBD.)\n",
    "    # For the latest updates, etc., please visit: www.aliannajmaren.com\n",
    "\n",
    "    # Note: the parameter 'alpha' in the transfer function shows up in the transfer function derivative\n",
    "    #   and so is not included explicitly in these equations\n",
    "\n",
    "    # The equation for the actual dependence of the Summed Squared Error on a given bias-to-output\n",
    "    #   weight biasOutput(o) is:\n",
    "    #   partial(SSE)/partial(biasOutput(o)) = -alpha*E(o)*F(o)*[1-F(o)]*1, as '1' is the input from the bias.\n",
    "    # The transfer function derivative (transFuncDeriv) returned from computeTransferFnctnDeriv is given as:\n",
    "    #   transFuncDeriv =  alpha*NeuronOutput*(1.0 -NeuronOutput), as with the hidden-to-output weights.\n",
    "    # Therefore, we can write the equation for the partial(SSE)/partial(biasOutput(o)) as\n",
    "    #   partial(SSE)/partial(biasOutput(o)) = E(o)*transFuncDeriv\n",
    "    #   The parameter alpha is included in transFuncDeriv\n",
    "\n",
    "    # Unpack the output array length\n",
    "    outputArrayLength = arraySizeList[2]\n",
    "\n",
    "    deltaBiasOutputArray = np.zeros(\n",
    "        outputArrayLength\n",
    "    )  # initialize an array for the deltas\n",
    "    newBiasOutputWeightArray = np.zeros(\n",
    "        outputArrayLength\n",
    "    )  # initialize an array for the new output bias weights\n",
    "    transferFuncDerivArray = np.zeros(\n",
    "        outputArrayLength\n",
    "    )  # iniitalize an array for the transfer function\n",
    "\n",
    "    for node in range(outputArrayLength):  #  Number of hidden nodes\n",
    "        transferFuncDerivArray[node] = computeTransferFnctnDeriv(\n",
    "            outputArray[node], alpha\n",
    "        )\n",
    "\n",
    "    for node in range(\n",
    "        outputArrayLength\n",
    "    ):  #  Number of nodes in output array (same as number of output bias nodes)\n",
    "        partialSSE_w_BiasOutput = -errorArray[node] * transferFuncDerivArray[node]\n",
    "        deltaBiasOutputArray[node] = -eta * partialSSE_w_BiasOutput\n",
    "        newBiasOutputWeightArray[node] = (\n",
    "            biasOutputWeightArray[node] + deltaBiasOutputArray[node]\n",
    "        )\n",
    "\n",
    "    #    print ' '\n",
    "    #    print ' The previous biases for the output nodes are: '\n",
    "    #    print biasOutputWeightArray\n",
    "    #    print ' '\n",
    "    #    print ' The new biases for the output nodes are: '\n",
    "    #    print newBiasOutputWeightArray\n",
    "\n",
    "    return newBiasOutputWeightArray\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# Backpropagate weight changes onto the input-to-hidden connection weights\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "def backpropagateHiddenToInput(\n",
    "    alpha,\n",
    "    eta,\n",
    "    arraySizeList,\n",
    "    errorArray,\n",
    "    outputArray,\n",
    "    hiddenArray,\n",
    "    inputArray,\n",
    "    vWeightArray,\n",
    "    wWeightArray,\n",
    "    biasHiddenWeightArray,\n",
    "    biasOutputWeightArray,\n",
    "):\n",
    "\n",
    "    # The first step here applies a backpropagation-based weight change to the input-to-hidden wts w.\n",
    "    # Core equation for the second part of backpropagation:\n",
    "    # d(SSE)/dw(i,h) = -eta*alpha*F(h)(1-F(h))*Input(i)*sum(v(h,o)*Error(o))\n",
    "    # where:\n",
    "    # -- SSE = sum of squared errors, and only the error associated with a given output node counts\n",
    "    # -- w(i,h) is the connection weight w between the input node i and the hidden node h\n",
    "    # -- v(h,o) is the connection weight v between the hidden node h and the output node o\n",
    "    # -- alpha is the scaling term within the transfer function, often set to 1\n",
    "    # ---- (this is included in transfFuncDeriv)\n",
    "    # -- Error = Error(o) or error at the output node o; = Desired(o) - Actual(o)\n",
    "    # -- F = transfer function, here using the sigmoid transfer function\n",
    "    # ---- NOTE: in this second step, the transfer function is applied to the output of the hidden node,\n",
    "    # ------ so that F = F(h)\n",
    "    # -- Hidden(h) = the output of hidden node h (used in computing the derivative of the transfer function).\n",
    "    # -- Input(i) = the input at node i.\n",
    "\n",
    "    # Note that the training rate parameter is assigned in main; Greek letter \"eta,\" looks like n,\n",
    "    #   scales amount of change to connection weight\n",
    "\n",
    "    # Unpack the errorList and the vWeightArray\n",
    "\n",
    "    # We will DECREMENT the connection weight v by a small amount proportional to the derivative eqn\n",
    "    #   of the SSE w/r/t the weight w.\n",
    "    # This means, since there is a minus sign in that derivative, that we will add a small amount.\n",
    "    # (Decrementing is -, applied to a (-), which yields a positive.)\n",
    "\n",
    "    # For the actual derivation of this equation with MATCHING VARIABLE NAMES (easy to understand),\n",
    "    #   please consult: Brain-Based Computing, by AJ Maren (under development, Jan., 2017). Chpt. X.\n",
    "    #   (Meaning: exact chapter is still TBD.)\n",
    "    # For the latest updates, etc., please visit: www.aliannajmaren.com\n",
    "\n",
    "    # Note that the training rate parameter is assigned in main; Greek letter \"eta,\" looks like n,\n",
    "    #   scales amount of change to connection weight\n",
    "\n",
    "    # For the second step in backpropagation (computing deltas on the input-to-hidden weights)\n",
    "    #   we need the transfer function derivative is applied to the output at the hidden node\n",
    "\n",
    "    # Unpack array lengths\n",
    "    inputArrayLength = arraySizeList[0]\n",
    "    hiddenArrayLength = arraySizeList[1]\n",
    "    outputArrayLength = arraySizeList[2]\n",
    "\n",
    "    # Note: the parameter 'alpha' in the transfer function shows up in the transfer function derivative\n",
    "    #   and so is not included explicitly in these equations\n",
    "    transferFuncDerivHiddenArray = np.zeros(\n",
    "        hiddenArrayLength\n",
    "    )  # initialize an array for the transfer function deriv\n",
    "\n",
    "    for node in range(hiddenArrayLength):  #  Number of hidden nodes\n",
    "        transferFuncDerivHiddenArray[node] = computeTransferFnctnDeriv(\n",
    "            hiddenArray[node], alpha\n",
    "        )\n",
    "\n",
    "    errorTimesTFuncDerivOutputArray = np.zeros(outputArrayLength)  # initialize array\n",
    "    transferFuncDerivOutputArray = np.zeros(outputArrayLength)  # initialize array\n",
    "    weightedErrorArray = np.zeros(hiddenArrayLength)  # initialize array\n",
    "\n",
    "    for outputNode in range(outputArrayLength):  #  Number of output nodes\n",
    "        transferFuncDerivOutputArray[outputNode] = computeTransferFnctnDeriv(\n",
    "            outputArray[outputNode], alpha\n",
    "        )\n",
    "        errorTimesTFuncDerivOutputArray[outputNode] = (\n",
    "            errorArray[outputNode] * transferFuncDerivOutputArray[outputNode]\n",
    "        )\n",
    "\n",
    "    for hiddenNode in range(hiddenArrayLength):\n",
    "        weightedErrorArray[hiddenNode] = 0\n",
    "        for outputNode in range(outputArrayLength):  #  Number of output nodes\n",
    "            weightedErrorArray[hiddenNode] = (\n",
    "                weightedErrorArray[hiddenNode]\n",
    "                + vWeightArray[outputNode, hiddenNode]\n",
    "                * errorTimesTFuncDerivOutputArray[outputNode]\n",
    "            )\n",
    "\n",
    "    deltaWWtArray = np.zeros(\n",
    "        (hiddenArrayLength, inputArrayLength)\n",
    "    )  # initialize an array for the deltas\n",
    "    newWWeightArray = np.zeros(\n",
    "        (hiddenArrayLength, inputArrayLength)\n",
    "    )  # initialize an array for the new input-to-hidden weights\n",
    "\n",
    "    for row in range(\n",
    "        hiddenArrayLength\n",
    "    ):  #  Number of rows in input-to-hidden weightMatrix\n",
    "        # For an input-to-hidden weight matrix, the rows correspond to the number of hidden nodes,\n",
    "        #    and the columns correspond to the number of input nodes.\n",
    "        #    This creates an HxI matrix, which can be multiplied by the input node array (expressed as a column).\n",
    "\n",
    "        for col in range(inputArrayLength):  # number of columns in weightMatrix\n",
    "            partialSSE_w_W_Wts = (\n",
    "                -transferFuncDerivHiddenArray[row]\n",
    "                * inputArray[col]\n",
    "                * weightedErrorArray[row]\n",
    "            )\n",
    "            deltaWWtArray[row, col] = -eta * partialSSE_w_W_Wts\n",
    "            newWWeightArray[row, col] = wWeightArray[row, col] + deltaWWtArray[row, col]\n",
    "\n",
    "    #    print ' '\n",
    "    #    print ' The previous hidden-to-output connection weights are: '\n",
    "    #    print wWeightArray\n",
    "    #    print ' '\n",
    "    #    print ' The new hidden-to-output connection weights are: '\n",
    "    #    print newWWeightArray\n",
    "\n",
    "    return newWWeightArray\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# Backpropagate weight changes onto the bias-to-hidden connection weights\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "def backpropagateBiasHiddenWeights(\n",
    "    alpha,\n",
    "    eta,\n",
    "    arraySizeList,\n",
    "    errorArray,\n",
    "    outputArray,\n",
    "    hiddenArray,\n",
    "    inputArray,\n",
    "    vWeightArray,\n",
    "    wWeightArray,\n",
    "    biasHiddenWeightArray,\n",
    "    biasOutputWeightArray,\n",
    "):\n",
    "\n",
    "    # The first step here applies a backpropagation-based weight change to the hidden-to-output wts v.\n",
    "    # Core equation for the first part of backpropagation:\n",
    "    # d(SSE)/dv(h,o) = -alpha*Error*F(1-F)*Hidden(h)\n",
    "    # where:\n",
    "    # -- SSE = sum of squared errors, and only the error associated with a given output node counts\n",
    "    # -- v(h,o) is the connection weight v between the hidden node h and the output node o\n",
    "    # -- alpha is the scaling term within the transfer function, often set to 1\n",
    "    # ---- (this is included in transfFuncDeriv)\n",
    "    # -- Error = Error(o) or error at the output node o; = Desired(o) - Actual(o)\n",
    "    # -- F = transfer function, here using the sigmoid transfer function\n",
    "    # -- Hidden(h) = the output of hidden node h.\n",
    "\n",
    "    # Note that the training rate parameter is assigned in main; Greek letter \"eta,\" looks like n,\n",
    "    #   scales amount of change to connection weight\n",
    "\n",
    "    # We will DECREMENT the connection weight biasOutput by a small amount proportional to the derivative eqn\n",
    "    #   of the SSE w/r/t the weight biasOutput(o).\n",
    "    # This means, since there is a minus sign in that derivative, that we will add a small amount.\n",
    "    # (Decrementing is -, applied to a (-), which yields a positive.)\n",
    "\n",
    "    # For the actual derivation of this equation with MATCHING VARIABLE NAMES (easy to understand),\n",
    "    #   please consult: Brain-Based Computing, by AJ Maren (under development, Jan., 2017). Chpt. X.\n",
    "    #   (Meaning: exact chapter is still TBD.)\n",
    "    # For the latest updates, etc., please visit: www.aliannajmaren.com\n",
    "\n",
    "    # Unpack array lengths\n",
    "    inputArrayLength = arraySizeList[0]\n",
    "    hiddenArrayLength = arraySizeList[1]\n",
    "    outputArrayLength = arraySizeList[2]\n",
    "\n",
    "    # Compute the transfer function derivatives as a function of the output nodes.\n",
    "    # Note: As this is being done after the call to the backpropagation on the hidden-to-output weights,\n",
    "    #   the transfer function derivative computed there could have been used here; the calculations are\n",
    "    #   being redone here only to maintain module independence\n",
    "\n",
    "    errorTimesTFuncDerivOutputArray = np.zeros(outputArrayLength)  # initialize array\n",
    "    transferFuncDerivOutputArray = np.zeros(outputArrayLength)  # initialize array\n",
    "    weightedErrorArray = np.zeros(hiddenArrayLength)  # initialize array\n",
    "\n",
    "    transferFuncDerivHiddenArray = np.zeros(\n",
    "        hiddenArrayLength\n",
    "    )  # initialize an array for the transfer function deriv\n",
    "    partialSSE_w_BiasHidden = np.zeros(\n",
    "        hiddenArrayLength\n",
    "    )  # initialize an array for the partial derivative of the SSE\n",
    "    deltaBiasHiddenArray = np.zeros(\n",
    "        hiddenArrayLength\n",
    "    )  # initialize an array for the deltas\n",
    "    newBiasHiddenWeightArray = np.zeros(\n",
    "        hiddenArrayLength\n",
    "    )  # initialize an array for the new hidden bias weights\n",
    "\n",
    "    for node in range(hiddenArrayLength):  #  Number of hidden nodes\n",
    "        transferFuncDerivHiddenArray[node] = computeTransferFnctnDeriv(\n",
    "            hiddenArray[node], alpha\n",
    "        )\n",
    "\n",
    "    for outputNode in range(outputArrayLength):  #  Number of output nodes\n",
    "        transferFuncDerivOutputArray[outputNode] = computeTransferFnctnDeriv(\n",
    "            outputArray[outputNode], alpha\n",
    "        )\n",
    "        errorTimesTFuncDerivOutputArray[outputNode] = (\n",
    "            errorArray[outputNode] * transferFuncDerivOutputArray[outputNode]\n",
    "        )\n",
    "\n",
    "    for hiddenNode in range(hiddenArrayLength):\n",
    "        weightedErrorArray[hiddenNode] = 0\n",
    "        for outputNode in range(outputArrayLength):  #  Number of output nodes\n",
    "            weightedErrorArray[hiddenNode] = (\n",
    "                weightedErrorArray[hiddenNode]\n",
    "                + vWeightArray[outputNode, hiddenNode]\n",
    "                * errorTimesTFuncDerivOutputArray[outputNode]\n",
    "            )\n",
    "\n",
    "    # Note: the parameter 'alpha' in the transfer function shows up in the transfer function derivative\n",
    "    #   and so is not included explicitly in these equations\n",
    "\n",
    "    # ===>>> AJM needs to double-check these equations in the comments area\n",
    "    # ===>>> The code should be fine.\n",
    "    # The equation for the actual dependence of the Summed Squared Error on a given bias-to-output\n",
    "    #   weight biasOutput(o) is:\n",
    "    #   partial(SSE)/partial(biasOutput(o)) = -alpha*E(o)*F(o)*[1-F(o)]*1, as '1' is the input from the bias.\n",
    "    # The transfer function derivative (transFuncDeriv) returned from computeTransferFnctnDeriv is given as:\n",
    "    #   transFuncDeriv =  alpha*NeuronOutput*(1.0 -NeuronOutput), as with the hidden-to-output weights.\n",
    "    # Therefore, we can write the equation for the partial(SSE)/partial(biasOutput(o)) as\n",
    "    #   partial(SSE)/partial(biasOutput(o)) = E(o)*transFuncDeriv\n",
    "    #   The parameter alpha is included in transFuncDeriv\n",
    "\n",
    "    for hiddenNode in range(\n",
    "        hiddenArrayLength\n",
    "    ):  #  Number of rows in input-to-hidden weightMatrix\n",
    "        partialSSE_w_BiasHidden[hiddenNode] = (\n",
    "            -transferFuncDerivHiddenArray[hiddenNode] * weightedErrorArray[hiddenNode]\n",
    "        )\n",
    "        deltaBiasHiddenArray[hiddenNode] = -eta * partialSSE_w_BiasHidden[hiddenNode]\n",
    "        newBiasHiddenWeightArray[hiddenNode] = (\n",
    "            biasHiddenWeightArray[hiddenNode] + deltaBiasHiddenArray[hiddenNode]\n",
    "        )\n",
    "\n",
    "    return newBiasHiddenWeightArray\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# Procedure to print out a letter, given the number of the letter code\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "def printLetter(trainingDataList):\n",
    "\n",
    "    pixelArray = trainingDataList[1]\n",
    "    print(\" \")\n",
    "    gridWidth = 9\n",
    "    gridHeight = 9\n",
    "    iterAcrossRow = 0\n",
    "    iterOverAllRows = 0\n",
    "    while iterOverAllRows < gridHeight:\n",
    "        while iterAcrossRow < gridWidth:\n",
    "            arrayElement = pixelArray[iterAcrossRow + iterOverAllRows * gridWidth]\n",
    "            if arrayElement < 0.9:\n",
    "                printElement = \" \"\n",
    "            else:\n",
    "                printElement = \"X\"\n",
    "            print(printElement, end=\"\")\n",
    "            iterAcrossRow = iterAcrossRow + 1\n",
    "        print(\" \")\n",
    "        iterOverAllRows = iterOverAllRows + 1\n",
    "        iterAcrossRow = 0  # re-initialize so the row-print can begin again\n",
    "    print(\n",
    "        \"The data set is for the letter\",\n",
    "        trainingDataList[3],\n",
    "        \", which is alphabet number \",\n",
    "        trainingDataList[2],\n",
    "    )\n",
    "    if trainingDataList[0] > 25:\n",
    "        print(\"This is a variant pattern for letter \", trainingDataList[3])\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "# **************************************************************************************************#\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "# **************************************************************************************************#\n",
    "####################################################################################################\n",
    "#\n",
    "# The MAIN module comprising of calls to:\n",
    "#   (1) Welcome\n",
    "#   (2) Obtain neural network size specifications for a three-layer network consisting of:\n",
    "#       - Input layer\n",
    "#       - Hidden layer\n",
    "#       - Output layer (all the sizes are currently hard-coded to two nodes per layer right now)\n",
    "#   (3) Initialize connection weight values\n",
    "#       - w: Input-to-Hidden nodes\n",
    "#       - v: Hidden-to-Output nodes\n",
    "#   (4) Compute a feedforward pass in two steps\n",
    "#       - Randomly select a single training data set\n",
    "#       - Input-to-Hidden\n",
    "#       - Hidden-to-Output\n",
    "#       - Compute the error array\n",
    "#       - Compute the new Summed Squared Error (SSE)\n",
    "#   (5) Perform a single backpropagation training pass\n",
    "#\n",
    "####################################################################################################\n",
    "# **************************************************************************************************#\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "def main(n_hidden, n_training, n_output, noise):\n",
    "\n",
    "    # Define the global variables\n",
    "    global inputArrayLength\n",
    "    global hiddenArrayLength\n",
    "    global outputArrayLength\n",
    "    global gridWidth\n",
    "    global gridHeight\n",
    "    global eGH  # expandedGridHeight, defined in function expandLetterBoundaries\n",
    "    global eGW  # expandedGridWidth defined in function expandLetterBoundaries\n",
    "    global mask1\n",
    "\n",
    "    ####################################################################################################\n",
    "    # Obtain unit array size in terms of array_length (M) and layers (N)\n",
    "    ####################################################################################################\n",
    "\n",
    "    # This calls the procedure 'welcome,' which just prints out a welcoming message.\n",
    "    # All procedures need an argument list.\n",
    "    # This procedure has a list, but it is an empty list; welcome().\n",
    "\n",
    "    #    welcome()\n",
    "\n",
    "    # Right now, for simplicity, we're going to hard-code the numbers of layers that we have in our\n",
    "    #   multilayer Perceptron (MLP) neural network.\n",
    "    # We will have an input layer (I), an output layer (O), and a single hidden layer (H).\n",
    "\n",
    "    # Define the variable arraySizeList, which is a list. It is initially an empty list.\n",
    "    # Its purpose is to store the size of the array.\n",
    "\n",
    "    arraySizeList = list()  # empty list\n",
    "\n",
    "    # Obtain the actual sizes for each layer of the network\n",
    "    arraySizeList = obtainNeuralNetworkSizeSpecs(n_hidden, n_output)\n",
    "\n",
    "    # Unpack the list; ascribe the various elements of the list to the sizes of different network layers\n",
    "    # Note: A word on Python encoding ... the actually length of the array, in each of these three cases,\n",
    "    #       will be xArrayLength. For example, the inputArrayLength for the 9x9 pixel array is 81.\n",
    "    #       These values are passed to various procedures. They start filling in actual array values,\n",
    "    #       where the array values start their count at element 0. However, when filling them in using a\n",
    "    #       \"for node in range[limit]\" statement, the \"for\" loop fills from 0 up to limit-1. Thus, the\n",
    "    #       original xArrayLength size is preserved.\n",
    "    inputArrayLength = arraySizeList[0]\n",
    "    hiddenArrayLength = arraySizeList[1]\n",
    "    outputArrayLength = arraySizeList[2]\n",
    "\n",
    "    print()\n",
    "    print(\" inputArrayLength = \", inputArrayLength)\n",
    "    print(\" hiddenArrayLength = \", hiddenArrayLength)\n",
    "    print(\" outputArrayLength = \", outputArrayLength)\n",
    "\n",
    "    # Parameter definitions for backpropagation, to be replaced with user inputs\n",
    "    alpha = 1.0\n",
    "    eta = 0.2\n",
    "    maxNumIterations = 100000  # temporarily set to 10 for testing\n",
    "    epsilon = 0.01\n",
    "    iteration = 0\n",
    "    SSE = 0.0\n",
    "    numTrainingDataSets = n_training\n",
    "\n",
    "    ####################################################################################################\n",
    "    # Initialize the weight arrays for two sets of weights; w: input-to-hidden, and v: hidden-to-output\n",
    "    ####################################################################################################\n",
    "\n",
    "    #\n",
    "    # The wWeightArray is for Input-to-Hidden\n",
    "    # The vWeightArray is for Hidden-to-Output\n",
    "\n",
    "    wWeightArraySizeList = (inputArrayLength, hiddenArrayLength)\n",
    "    vWeightArraySizeList = (hiddenArrayLength, outputArrayLength)\n",
    "    biasHiddenWeightArraySize = hiddenArrayLength\n",
    "    biasOutputWeightArraySize = outputArrayLength\n",
    "\n",
    "    # The node-to-node connection weights are stored in a 2-D array\n",
    "\n",
    "    wWeightArray = initializeWeightArray(wWeightArraySizeList)\n",
    "\n",
    "    vWeightArray = initializeWeightArray(vWeightArraySizeList)\n",
    "\n",
    "    # The bias weights are stored in a 1-D array\n",
    "    biasHiddenWeightArray = initializeBiasWeightArray(biasHiddenWeightArraySize)\n",
    "    biasOutputWeightArray = initializeBiasWeightArray(biasOutputWeightArraySize)\n",
    "\n",
    "    ####################################################################################################\n",
    "    # Starting the backpropagation work\n",
    "    ####################################################################################################\n",
    "\n",
    "    # Notice in the very beginning of the program, we have\n",
    "    #   np.set_printoptions(precision=4) (sets number of dec. places in print)\n",
    "    #     and 'np.set_printoptions(suppress=True)', which keeps it from printing in scientific format\n",
    "    #   Debug print:\n",
    "    #    print\n",
    "    #    print 'The initial weights for this neural network are:'\n",
    "    #    print '       Input-to-Hidden '\n",
    "    #    print wWeightArray\n",
    "    #    print '       Hidden-to-Output'\n",
    "    #    print vWeightArray\n",
    "    #    print ' '\n",
    "    #    print 'The initial bias weights for this neural network are:'\n",
    "    #    print '        Hidden Bias = ', biasHiddenWeightArray\n",
    "    #    print '        Output Bias = ', biasOutputWeightArray\n",
    "\n",
    "    ####################################################################################################\n",
    "    # Before we start training, get a baseline set of outputs, errors, and SSE\n",
    "    ####################################################################################################\n",
    "\n",
    "    print()\n",
    "    print(\"  Before training:\")\n",
    "\n",
    "    ComputeOutputsAcrossAllTrainingData(\n",
    "        alpha,\n",
    "        numTrainingDataSets,\n",
    "        wWeightArray,\n",
    "        biasHiddenWeightArray,\n",
    "        vWeightArray,\n",
    "        biasOutputWeightArray,\n",
    "        arraySizeList,\n",
    "    )\n",
    "\n",
    "    ####################################################################################################\n",
    "    # Next step - Obtain a single set of randomly-selected training values for alpha-classification\n",
    "    ####################################################################################################\n",
    "\n",
    "    while iteration < maxNumIterations:\n",
    "\n",
    "        # Increment the iteration count\n",
    "        iteration = iteration + 1\n",
    "\n",
    "        ####################################################################################################\n",
    "        # While training - STEP 1: Obtain a set of training data; inputs and desired outputs\n",
    "        ####################################################################################################\n",
    "\n",
    "        # For any given pass, we re-initialize the training list\n",
    "        trainingDataList = (\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            \" \",\n",
    "        )\n",
    "\n",
    "        # Randomly select one of 48 training sets; the inputs will be randomly assigned to 0 or 1\n",
    "        dataSet = random.randint(0, numTrainingDataSets - 1)\n",
    "\n",
    "        # We return the list from the function, with values placed inside the list.\n",
    "        trainingDataList = obtainSelectedAlphabetTrainingValues(dataSet)\n",
    "\n",
    "        # Optional print/debug\n",
    "        #        printLetter(trainingDataList)\n",
    "\n",
    "        ####################################################################################################\n",
    "        # While training - STEP 2: Create an input array based on the input training data list\n",
    "        ####################################################################################################\n",
    "\n",
    "        inputDataList = []\n",
    "        inputDataArray = np.zeros(inputArrayLength)\n",
    "\n",
    "        # The trainning inputs are drawn from the first element (starting count at 0) in the training data list\n",
    "\n",
    "        thisTrainingDataList = list()\n",
    "        thisTrainingDataList = trainingDataList[1]\n",
    "        for node in range(inputArrayLength):\n",
    "            trainingData = thisTrainingDataList[node]\n",
    "\n",
    "            # add in noise 10% of the time\n",
    "\n",
    "            if random.randint(0, 1) < noise:\n",
    "                if trainingData == 0:\n",
    "                    trainingData = 1\n",
    "                if trainingData == 1:\n",
    "                    trainingData = 0\n",
    "\n",
    "            inputDataList.append(trainingData)\n",
    "            inputDataArray[node] = trainingData\n",
    "\n",
    "        # The desired outputs are drawn from the fourth element (starting count at 0) in the training data list\n",
    "        #   This represents the \"big shape class\" which we are training towards in GB1\n",
    "\n",
    "        desiredOutputArray = np.zeros(\n",
    "            outputArrayLength\n",
    "        )  # iniitalize the output array with 0's\n",
    "        desiredClass = trainingDataList[4]  # identify the desired class\n",
    "        desiredOutputArray[\n",
    "            desiredClass\n",
    "        ] = 1  # set the desired output for that class to 1\n",
    "\n",
    "        ####################################################################################################\n",
    "        # Compute a single feed-forward pass and obtain the Actual Outputs\n",
    "        ####################################################################################################\n",
    "\n",
    "        hiddenArray = ComputeSingleFeedforwardPassFirstStep(\n",
    "            alpha, inputDataArray, wWeightArray, biasHiddenWeightArray\n",
    "        )\n",
    "\n",
    "        outputArray = ComputeSingleFeedforwardPassSecondStep(\n",
    "            alpha, hiddenArray, vWeightArray, biasOutputWeightArray\n",
    "        )\n",
    "\n",
    "        #  Optional alternative code for later use:\n",
    "        #  Assign the hidden and output values to specific different variables\n",
    "        #    for node in range(hiddenArrayLength):\n",
    "        #        actualHiddenOutput[node] = actualAllNodesOutputList [node]\n",
    "\n",
    "        #    for node in range(outputArrayLength):\n",
    "        #        actualOutput[node] = actualAllNodesOutputList [hiddenArrayLength + node]\n",
    "\n",
    "        # Initialize the error array\n",
    "        errorArray = np.zeros(outputArrayLength)\n",
    "\n",
    "        # Determine the error between actual and desired outputs\n",
    "        newSSE = 0.0\n",
    "        for node in range(\n",
    "            outputArrayLength\n",
    "        ):  #  Number of nodes in output set (classes)\n",
    "            errorArray[node] = desiredOutputArray[node] - outputArray[node]\n",
    "            newSSE = newSSE + errorArray[node] * errorArray[node]\n",
    "\n",
    "        ####################################################################################################\n",
    "        # Perform backpropagation\n",
    "        ####################################################################################################\n",
    "\n",
    "        # Perform first part of the backpropagation of weight changes\n",
    "        newVWeightArray = backpropagateOutputToHidden(\n",
    "            alpha,\n",
    "            eta,\n",
    "            arraySizeList,\n",
    "            errorArray,\n",
    "            outputArray,\n",
    "            hiddenArray,\n",
    "            vWeightArray,\n",
    "        )\n",
    "        newBiasOutputWeightArray = backpropagateBiasOutputWeights(\n",
    "            alpha, eta, arraySizeList, errorArray, outputArray, biasOutputWeightArray\n",
    "        )\n",
    "\n",
    "        # Perform first part of the backpropagation of weight changes\n",
    "        newWWeightArray = backpropagateHiddenToInput(\n",
    "            alpha,\n",
    "            eta,\n",
    "            arraySizeList,\n",
    "            errorArray,\n",
    "            outputArray,\n",
    "            hiddenArray,\n",
    "            inputDataList,\n",
    "            vWeightArray,\n",
    "            wWeightArray,\n",
    "            biasHiddenWeightArray,\n",
    "            biasOutputWeightArray,\n",
    "        )\n",
    "\n",
    "        newBiasHiddenWeightArray = backpropagateBiasHiddenWeights(\n",
    "            alpha,\n",
    "            eta,\n",
    "            arraySizeList,\n",
    "            errorArray,\n",
    "            outputArray,\n",
    "            hiddenArray,\n",
    "            inputDataList,\n",
    "            vWeightArray,\n",
    "            wWeightArray,\n",
    "            biasHiddenWeightArray,\n",
    "            biasOutputWeightArray,\n",
    "        )\n",
    "\n",
    "        # Assign new values to the weight matrices\n",
    "        # Assign the old hidden-to-output weight array to be the same as what was returned from the BP weight update\n",
    "        vWeightArray = newVWeightArray[:]\n",
    "\n",
    "        biasOutputWeightArray = newBiasOutputWeightArray[:]\n",
    "\n",
    "        # Assign the old input-to-hidden weight array to be the same as what was returned from the BP weight update\n",
    "        wWeightArray = newWWeightArray[:]\n",
    "\n",
    "        biasHiddenWeightArray = newBiasHiddenWeightArray[:]\n",
    "\n",
    "        # Compute a forward pass, test the new SSE\n",
    "\n",
    "        hiddenArray = ComputeSingleFeedforwardPassFirstStep(\n",
    "            alpha, inputDataList, wWeightArray, biasHiddenWeightArray\n",
    "        )\n",
    "\n",
    "        outputArray = ComputeSingleFeedforwardPassSecondStep(\n",
    "            alpha, hiddenArray, vWeightArray, biasOutputWeightArray\n",
    "        )\n",
    "\n",
    "        # Determine the error between actual and desired outputs\n",
    "\n",
    "        newSSE = 0.0\n",
    "        for node in range(\n",
    "            outputArrayLength\n",
    "        ):  #  Number of nodes in output set (classes)\n",
    "            errorArray[node] = desiredOutputArray[node] - outputArray[node]\n",
    "            newSSE = newSSE + errorArray[node] * errorArray[node]\n",
    "\n",
    "        if newSSE < epsilon:\n",
    "            break\n",
    "    print(\"Out of while loop at iteration \", iteration)\n",
    "\n",
    "    ####################################################################################################\n",
    "    # After training, get a new comparative set of outputs, errors, and SSE\n",
    "    ####################################################################################################\n",
    "\n",
    "    # print()\n",
    "    # print(\"  After training:\")\n",
    "    HN_activ_list = ComputeOutputsAcrossAllTrainingData(\n",
    "        alpha,\n",
    "        numTrainingDataSets,\n",
    "        wWeightArray,\n",
    "        biasHiddenWeightArray,\n",
    "        vWeightArray,\n",
    "        biasOutputWeightArray,\n",
    "        arraySizeList,\n",
    "    )\n",
    "    # save the weight arrays\n",
    "    # saveWeights(inputArrayLength, hiddenArrayLength, outputArrayLength, wWeightArray, vWeightArray, biasHiddenWeightArray, biasOutputWeightArray)\n",
    "\n",
    "    # print ' for the last training data set:'\n",
    "    # printLetter(trainingDataList)\n",
    "\n",
    "    return iteration, HN_activ_list\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "# Conclude specification of the MAIN procedure\n",
    "####################################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0clqMleVB0v"
   },
   "source": [
    "#### Letter Grid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jviZe-gsxaqr",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# visLetterInputs: print out each letter as a heat map, both grid and flat\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "# def visLetterInputs(numLetters):\n",
    "# for letter in range(5):\n",
    "# get the letter input values out\n",
    "letterVals = obtainSelectedAlphabetTrainingValues(27)\n",
    "letterList = np.asarray(letterVals[1])\n",
    "# split into a 9x9 grid and 1x81 grid\n",
    "letterGridVals = np.split(letterList, 9)\n",
    "letterFlatVals = np.split(letterList, 1)\n",
    "\n",
    "\n",
    "# plot the two on a subplot\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=False, sharey=False)\n",
    "fig.set_size_inches(30, 15)\n",
    "\n",
    "# print the letter values as matrix\n",
    "ax1.imshow(letterGridVals, cmap=plt.cm.Greys)\n",
    "# add in the input node labels\n",
    "idx = 0\n",
    "for (j, _) in np.ndenumerate(letterGridVals):\n",
    "    ax1.text(\n",
    "        j[1],\n",
    "        j[0],\n",
    "        idx,\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"white\"),\n",
    "    )\n",
    "    idx += 1\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "# print as a flat line\n",
    "ax2.imshow(letterFlatVals, cmap=plt.cm.Greys)\n",
    "# add in the input node labels\n",
    "idx = 0\n",
    "for (j, _) in np.ndenumerate(letterFlatVals):\n",
    "    ax2.text(\n",
    "        j[1],\n",
    "        j[0],\n",
    "        idx,\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"white\"),\n",
    "    )\n",
    "    idx += 1\n",
    "# loc = plticker.MultipleLocator(base=1.0)\n",
    "# ax2.xaxis.set_major_locator(loc)\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "\n",
    "filename = \"letter_{}_input.png\".format(letterVals[26])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "smHmxp0SVPuP"
   },
   "source": [
    "### Top-level driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8789,
     "status": "ok",
     "timestamp": 1589341098815,
     "user": {
      "displayName": "Chris Rico",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHHfN9cEcyW0UKEYRqrJJRVc7VtUuJszJ9nM8=s64",
      "userId": "02883936081336753861"
     },
     "user_tz": 420
    },
    "id": "tpDi4botVPKU",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "2b298eea-bd28-49be-ae7c-8cd16a747d1e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list to hold number of hidden nodes to run - update as desired\n",
    "numberOfHiddenNodes = 6\n",
    "numberOfTrainingDataSets = len(trainingDataList)\n",
    "numberOfClasses = 8\n",
    "noise = 0.1\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "# make df to store iteration training data\n",
    "iter_results_DF = pd.DataFrame(\n",
    "    columns=[\"Number Hidden Nodes\", \"Percent noise\", \"Iterations to Epsilon\"]\n",
    ")\n",
    "\n",
    "# run the model and get results\n",
    "print(\"\\n\\n\\n ###########################################\")\n",
    "print(\"Model Ouput with {} hidden nodes\".format(numberOfHiddenNodes))\n",
    "iterations, hn_activ_list = main(\n",
    "    numberOfHiddenNodes, numberOfTrainingDataSets, numberOfClasses, noise\n",
    ")\n",
    "\n",
    "results_df = build_df(numberOfHiddenNodes, hn_activ_list)\n",
    "\n",
    "\"\"\"\n",
    "#store the iteration results\n",
    "iter_results_DF = iter_results_DF.append({\n",
    "                                          'Number Hidden Nodes' : numberOfHiddenNodes,\n",
    "                                          'Percent noise' : percent,\n",
    "                                          'Iterations to Epsilon' : iterations\n",
    "                                        },\n",
    "                                        sort=False,\n",
    "                                        ignore_index=True\n",
    "                                        )\n",
    "\n",
    "#generate the results df\n",
    "results_df = build_df(numberOfHiddenNodes, hn_activ_list)\n",
    "#makeOutputViz(numberOfHiddenNodes, numberOfTrainingDataSets)\n",
    "print(\"Num Iterations {}\".format(iterations))\n",
    "\n",
    "#generate bar chart of iterations per num hidden nodes\n",
    "sns.barplot(iter_results_DF.iloc[:,0], iter_results_DF.iloc[:,1]).set_title=(\"Iterations to Epsilon 0.01\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6L-sKtl9VG5G"
   },
   "source": [
    "#### Results DF builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBXMPL7Fw1sy",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "####################################################################################################\n",
    "#\n",
    "# build_df: build a results df\n",
    "#\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "def build_df(n_hidden_nodes, hn_activ_list):\n",
    "    input_grid_size = 81\n",
    "    num_chars = len(trainingDataList)\n",
    "\n",
    "    # get column names\n",
    "    df_cols = [\"Big Letter\", \"Small Letter\"]\n",
    "    for node in range(0, input_grid_size):\n",
    "        input_node = \"IN_{}\".format(node)\n",
    "        df_cols.append(input_node)\n",
    "\n",
    "    # get the input node values into the respective columns\n",
    "    node_values = np.empty([num_chars, 0])\n",
    "    for n in range(0, num_chars):\n",
    "        # get the input values\n",
    "        letterVals = obtainSelectedAlphabetTrainingValues(n)\n",
    "        # append the big letter and small letter class vals\n",
    "        node_values = np.append(node_values, letterVals[5])\n",
    "        node_values = np.append(node_values, letterVals[3])\n",
    "        # append the input node values\n",
    "        node_values = np.append(node_values, letterVals[1][:])\n",
    "\n",
    "    # split the array into appropriate number of sub-frames\n",
    "    node_values = np.split(node_values, num_chars)\n",
    "    # define and populate the dataframe\n",
    "    results_DF = pd.DataFrame(data=node_values, columns=df_cols)\n",
    "\n",
    "    # get the hidden nodes\n",
    "    df_cols = []\n",
    "    for node in range(0, n_hidden_nodes):\n",
    "        hidden_node = \"HN_{}\".format(node)\n",
    "        df_cols.append(hidden_node)\n",
    "\n",
    "    h_n_values = np.empty([num_chars, 0])\n",
    "    # now get the hidden layer values\n",
    "    for letter in hn_activ_list:\n",
    "        h_n_values = np.append(h_n_values, letter[4])\n",
    "\n",
    "    h_n_values = np.split(h_n_values, num_chars)\n",
    "\n",
    "    # define the dataframe\n",
    "    acti_results_df = pd.DataFrame(data=h_n_values, columns=df_cols)\n",
    "    # merge the two to get one df\n",
    "    results = results_DF.merge(acti_results_df, left_index=True, right_index=True)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qei_Nw9mDpNk"
   },
   "source": [
    "### Output visuzalization generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2395,
     "status": "ok",
     "timestamp": 1589339807359,
     "user": {
      "displayName": "Chris Rico",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHHfN9cEcyW0UKEYRqrJJRVc7VtUuJszJ9nM8=s64",
      "userId": "02883936081336753861"
     },
     "user_tz": 420
    },
    "id": "RMmHbcL1ugtj",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "f10df567-9487-46ae-8b59-3c477bb9a005",
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_arr = np.asarray(results_df.loc[:, \"IN_0\":\"IN_80\"].astype(float)).T\n",
    "hn_arr = np.asarray(results_df.loc[:, \"HN_0\":].astype(float)).T\n",
    "\n",
    "for node in range(0, hn_arr.shape[0]):\n",
    "    out_arr = np.multiply(in_arr, hn_arr[node])\n",
    "    out_arr_avg = np.mean(out_arr, axis=1)\n",
    "\n",
    "    print(out_arr_avg.max())\n",
    "    out_heatmap = np.split(out_arr_avg, 9)\n",
    "    print(\"HN {}\".format(node))\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "        out_heatmap,\n",
    "        cbar=False,\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Km30QRVFNxtF"
   },
   "source": [
    "### Big Class Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10600,
     "status": "ok",
     "timestamp": 1589341127064,
     "user": {
      "displayName": "Chris Rico",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHHfN9cEcyW0UKEYRqrJJRVc7VtUuJszJ9nM8=s64",
      "userId": "02883936081336753861"
     },
     "user_tz": 420
    },
    "id": "GIfuP50RdjvB",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "6d71759f-745a-4887-d9ce-604a826d051a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nodes per big class\n",
    "# sort the df so all the big letter classes are together\n",
    "results_df.sort_values([\"Big Letter\"], ascending=True, inplace=True, ignore_index=True)\n",
    "# get a list of all the unique big char classes\n",
    "letter_classes = results_df[\"Big Letter\"].unique()\n",
    "\n",
    "for letter_class in letter_classes:\n",
    "    df = results_df[results_df[\"Big Letter\"] == letter_class]\n",
    "    uniques = df[\"Small Letter\"].unique()\n",
    "\n",
    "    in_arr = np.asarray(df.loc[:, \"IN_0\":\"IN_80\"].astype(float)).T\n",
    "    hn_arr = np.asarray(df.loc[:, \"HN_0\":].astype(float)).T\n",
    "\n",
    "    print(\"\\n\\n############  Class {} ############\".format(letter_class))\n",
    "    print(\"Unique Letters: {}\".format(uniques))\n",
    "    for node in range(0, hn_arr.shape[0]):\n",
    "        out_arr = np.multiply(in_arr, hn_arr[node])\n",
    "        out_arr_avg = np.mean(out_arr, axis=1)\n",
    "\n",
    "        out_heatmap = np.split(out_arr_avg, 9)\n",
    "        print(\"HN {}\".format(node))\n",
    "\n",
    "        ax = sns.heatmap(\n",
    "            out_heatmap,\n",
    "            cbar=False,\n",
    "        )\n",
    "        plt.show()\n",
    "        plt.clf()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "P0clqMleVB0v",
    "6L-sKtl9VG5G"
   ],
   "name": "A2 Big Shape Classes.ipynb",
   "provenance": [
    {
     "file_id": "1GmIDh544wDYS0W1gmf_jSeVKHSmVRzCz",
     "timestamp": 1589311267016
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
